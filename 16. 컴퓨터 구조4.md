# 16. 컴퓨터 구조4

## 메모리 계층

### 메모리의 범위와 종류

1. 메인 메모리(RAM) - D-RAM계열의 메모리
2. 레지스터 - CPU안에 내장되어 있어서 연산을 위한 저장소 제공
3. 캐쉬 - CPU와 RAM사이에서 중간 저장소 역할을 하는 메모리. 캐쉬 메모리는 CPU의 일부로 존재하는 메모리 개념이 아니라, CPU에 근접해 있는 메모리 개념임
4. 하드 디스크와 이외의 저장 장치들 - 하드디스크도 당연히 메모리. 그 밖에 SD 카드, CD-ROM와 같은 I/O장치들도 메모리에 해당함

**프로그래머는 레지스터, 캐쉬, 메인 메모리, 하드디스크 뿐만 아니라 그 밖의 I/O장치들과의 입출력 타이밍 및 대기 시간 등을 가장 중요한 요소로 생각하고 항상 고민해야 한다**

### 메모리 계층 구조

- 메모리의 역할 - 데이터의 입력 및 출력
- 각 메모리의 차이점 - CPU를 기준으로 얼마나 멀리 떨어져있는가(가까울 수록 빠르고 멀수록 느리다)
- CPU근처로 대용량의 메모리를 가져 갈수록 기술적인 문제들과 비용이 훨씬 많이 들기 때문에 메모리 계층 구조를 사용함

1. 레지스터
2. L1캐쉬 - L2캐쉬보다 CPU에 근접해있음
3. L2캐쉬
4. 메인 메모리
5. 하드디스크

- 모든 메모리의 역할이 피라미드 구조에서 자신보다 아래에 있는 메모리를 캐쉬(자주 사용되는 메모리의 일부를 저장해서 속도를 향상시키는 것)하기 위해 존재
- 메인 메모리를 제외한 L1캐쉬와 L2캐쉬에, 연산에 필요한 데이터가 존재할 확률이 90% 이상 되기 때문에 하드디스크에서 데이터를 읽어들이는 빈도수는 전체 메모리 접근 빈도수의 불과 몇 퍼센트도 되지 않음.
- 따라서 캐쉬는 속도를 아주 많이 향상시킴

### L1 캐쉬와 L2 캐쉬

- 시스템의 성능을 좌우하는 클럭속도는 항상 느린 쪽에 맞춰지게 되어있음
- CPU는 상당히 고속화되어 그만큼 메모리의 처리속도는 CPU를 따라가지 못함
- 이 때, CPU와 메모리의 처리속도가 커지게 되면 클럭은 느린쪽에 맞춰지게 되어 CPU의 성능을 제대로 낼 수 없게 됨(병목현상 발생)
- 따라서, 자주 사용되는 주소 번지의 데이터는 캐쉬 메모리에 저장해둬서 메인 메모리까지 가야만 하는 빈도수를 줄여주게 된다.
- 병목현상을 최소화하기 위해서는 캐쉬의 사이즈를 줄이면 되지만, 한계가 있기 때문에 캐쉬를 중간에 하나 더 두게 되었다.
- 과거에는 캐쉬 메모리가 CPU바깥에 있었으나 현재는 CPU내부에 들어가게 되었음



## 캐쉬와 캐쉬 알고리즘

### 컴퓨터 프로그램의 일반적인 특성

- 템퍼럴 로컬리티 - 프로그램 실행 시 한 번 접근이 이뤄진 주소의 메모리 영역은 자주 접근하게 된다는 프로그램 특성
- 스페이셜 로컬리티 - 프로그램 실행 시 접근하는 메모리 영역은 이미 접근이 이루어진 영역의 근처일 확률이 높다는 프로그램 성격을 표현
- 캐쉬 프렌드리 코드 - 캐쉬의 도움을 많이 받을 수 있도록 구현된 코드

### 캐쉬 알고리즘

1. ALU연산과정 중에서 필요한 데이터가 있다면 이를 레지스터로 이동시켜야 함
2. 0x1000번지에 존재하는 데이터를 찾기 위해 L1캐쉬를 찾아봄
3. L1캐쉬에 해당 데이터가 존재하면(캐쉬 힛 발생) 데이터를 레지스터로 이동.
4. 존재하지 않는다면(캐쉬 미스 발생) L2 캐쉬에서 데이터를 찾아봄
5. 2~4반복.(주체가 L2, 메인 메모리로 바뀔 뿐)

- 이 때 단순히 필요로 하는 데이터만 보내는 것이 아니라, 블록 단위로 전송을 해서 스페이셜 로컬리티의 특성을 성능 향상에 십분 활용하게 된다.
- 운영체제가 동작을 하고, 프로그램이 실행되는 동안에는 하드디스크를 제외한 모든 메모리가 항상 채워져 있음(그래야 메모리를 갖고있을 확률이 높아짐)
- 따라서 L1캐쉬에서 캐쉬 미스가 발생해서 L2 캐쉬로부터 데이터 블록을 읽어 들일 때 어디에 저장할지에 대한 문제가 발생함
- 이 때 기존에 저장한 데이터를 밀어내는데 **캐쉬 교체 정책**에 따라 달라지는 블록 교체 알고리즘에 따라 작동한다.



## 가상 메모리

### 물리 주소(Physical Address)

램 용량이 16mb라고 했을 경우, 0번지부터 16 * 1024 * 1024 - 1번지 사이가 메모리 영역이 됨

이것이 실제 물리적인 메모리의 주소 범위에 해당이며, 이를 가리켜 물리적 주소 지정이라 함

### 가상 주소(Virtual Address) 시스템 1

32비트 프로그램에서 프로세스 생성 시 4GB의 메모리를 할당받을 수 있음. 그러나 메인 메모리의 크기는 이것에 비해 한없이 부족함. 따라서 4GB는 실제 존재하지 않는 가상의 주소를 사용한다.

- 가상 주소 지정 - 위와 같은 상황에서 가상의 주소를 지정하는 것을 가리킴
- 가상 메모리 공간 - 가상 주소 지정을 통해서 할당받게 되는 4GB를 가리킴
- MMU(Memory Management Unit) - 32비트 시스템을 예로들면 1GB밖에 존재하지 않는 메모리를 4GB가 존재하는 것처럼 CPU가 느끼도록 컨트롤하는 역할을 함(CPU와 함께 하나로 패키징 되는 장치)

#### 메모리 할당 과정(페이징 기법)

1. CPU가 MMU에게 n번지를 시작으로 x바이트 할당을 요청함
2. MMU는 메인 메모리에서 아직 사용되지 않는 메모리 블록 하나를 골라서 할당을 함(메모리 할당의 범위는 시스템마다 다름)
3. 블록의 단위를 16바이트 정도로 최소화하거나, 단위를 아예 없애버리고 필요한 만큼만 할당하게 될 경우 메모리 사용의 효율성은 증가함. 그러나 그만큼 MMU는 연산이 늘어나게 되고 속도가 감소하게 됨
4. 또한, 스페이셜 로컬리티의 특성으로 인해 블록 단위로 할당받는 것은 불필요한 할당이 아님
5. 이러한 블록을 하드웨어 입장에서는 **페이지 프레임** 이라고 함
6. 소프트웨어 입장에서는 **페이지**라고 함.

### 가상주소 시스템2

- 하드디스크 - 램과 비교해서 속도를 제외하면 그 기능에 있어서 조금도 부족함이 없는 메모리임
- 이러한 하드디스크를 메인 메모리로 확장해서 문제를 해결할 수 있음(스왑 파일 개념)
- 하드디스크의 역할 - 기존의 메인 메모리에 여유 공간이 없어 메모리를 할당할 방법이 없으면 특정 메모리 블록을 하드디스크에 저장하고 나서 그 영역을 새롭게 할당하는 수밖에 없음. 만약 새로운 할당 이후 하드 디스크에 저장한 블록의 영역 접근이 발생하면 다시 꺼내오는 수밖에없다.
- 둘 이상의 프로세스에게 4GB씩 할당이 가능한 이유 - 프로세스A가 실행을 멈추고 프로세스 B를 실행시키고자 한다면 램에 존재하는 프로세스 A의 실행을 위한 데이터 모두를 프로세스 A의 스왑 파일에 저장 후 프로세스 B의 실행을 위한 데이터를 프로세스 B의 스왑파일로부터 램에 가져다놓음. 이러한 일련의 과정을 반복.